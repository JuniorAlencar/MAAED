{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from time import process_time\n",
    "import math\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_total_data(num_threads):\n",
    "    df1 = pd.read_csv(\"../data/dictonary_user.txt\", sep=\" \")\n",
    "    N = df1.shape[0]\n",
    "    time_1_sample = 0.9207201502000032\n",
    "    time_days = (df1.shape[0]*time_1_sample)/(60*60*24*num_threads) #dias\n",
    "    return print(time_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_samples_for_hour(hour):\n",
    "    time_1_sample = 0.9207201502000032\n",
    "    num_samples_hour = (360*hour)/time_1_sample\n",
    "    return math.ceil(int(num_samples_hour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_txt():\n",
    "    # Aumenta o limite que a biblioteca csv consegue abrir arquivos. 300mb.\n",
    "    csv.field_size_limit(300 * 1024 * 1024)\n",
    "\n",
    "    path = \"../data\"\n",
    "    all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    if(len(all_files)==0):\n",
    "        pass\n",
    "    else:\n",
    "        # Função para remover espaços e tabulações extras e substituí-los por um único espaço\n",
    "        def remove_spaces_and_tabs(input_string):\n",
    "            return ' '.join(input_string.split())\n",
    "\n",
    "        for file in all_files:\n",
    "            file_original = os.path.basename(file)\n",
    "            file_txt = os.path.join(path, file_original[:-4] + \".txt\")\n",
    "            \n",
    "            with open(file, \"r\", encoding=\"utf-8\") as csv_file, open(file_txt, \"w\",encoding=\"utf-8\") as txt_file:\n",
    "                csv_reader = csv.reader(csv_file)\n",
    "                for row in csv_reader:\n",
    "                    # Remove espaços e tabulações extras e substituir por um único espaço\n",
    "                    cleaned_row = [remove_spaces_and_tabs(field) for field in row]\n",
    "                    \n",
    "                    #Escreve os campos no arquivo txt separados por espaços\n",
    "                    txt_file.write(\" \".join(cleaned_row) + \"\\n\")\n",
    "\n",
    "            print(f\"Dados do arquivo '{file}' foram processados e salvos em '{file_txt}'\")\n",
    "            # Remove os arquivos .csv após a conversão\n",
    "            os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictonary_name_users():\n",
    "    \n",
    "    file_path = \"../data/dictonary_user.txt\"\n",
    "    if os.path.exists(file_path):\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        df = pd.read_csv(\"./data/user_user.txt\",sep=\" \") # open file\n",
    "        df = df[[\"userA\",\"userB\"]].copy() # Create dataframe from df (all data) just with [userA, userB] columns\n",
    "        unique_names = pd.unique(df.values.flatten()) # unique values in dataframe\n",
    "        #data_2 = [str(i) for i in df[\"userB\"].values]    # List of name in userB column\n",
    "        #data_T = data_1 + data_2                         # List of all of users\n",
    "\n",
    "        N = len(unique_names)                            # Total number of users\n",
    "        dict_users = np.arange(0,N,1)                    # Create range to dictionary of users_names\n",
    "        dictonary = [f\"{i:06d}\" for i in dict_users]     # dictonary with number [0, N] with same digitals number\n",
    "\n",
    "        dict_converted = {}                              # Dictonary with {name:cod_name}\n",
    "        dict_converted[\"name\"] = unique_names\n",
    "        dict_converted[\"cod_name\"] = dictonary\n",
    "        df1 = pd.DataFrame(data=dict_converted)\n",
    "        df1.to_csv(file_path,sep=\" \",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"./data/user_user.txt\", sep=\" \") # open user_user\n",
    "# df = df[[\"userA\",\"userB\"]].copy()                 #\n",
    "\n",
    "# df[\"userA\"] = df[\"userA\"].astype(\"str\")\n",
    "# df[\"userB\"] = df[\"userB\"].astype(\"str\")\n",
    "\n",
    "# sorted_df = pd.DataFrame(np.sort(df[['userA', 'userB']], axis=1), columns=['userA', 'userB'])\n",
    "# unique_pairs_df = sorted_df.drop_duplicates()\n",
    "# unique_pairs_df.reset_index(drop=True, inplace=True)\n",
    "# unique_pairs_df.to_csv(\"./data/user_user.txt\",sep=\" \",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/junior/Documents/codes/MAAED/Animes/codes/fix_data.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/junior/Documents/codes/MAAED/Animes/codes/fix_data.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file_path, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/junior/Documents/codes/MAAED/Animes/codes/fix_data.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     lines \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mreadlines()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/junior/Documents/codes/MAAED/Animes/codes/fix_data.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m columns \u001b[39m=\u001b[39m lines[target_row]\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m)  \u001b[39m# Assuming columns are separated by tabs ('\\t')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/junior/Documents/codes/MAAED/Animes/codes/fix_data.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m columns[target_column] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/junior/Documents/codes/MAAED/Animes/codes/fix_data.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m lines[target_row] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(columns) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Define the file path\n",
    "file_path = \"../data/user_user.txt\"\n",
    "\n",
    "# Specify the row and column you want to modify (0-based index)\n",
    "target_row = 0  # For example, modify the third row (index 2)\n",
    "target_column = 3  # Modify the second column (index 1)\n",
    "\n",
    "# New value to be written to the specific row and column\n",
    "new_value = \"friendship_time\"\n",
    "\n",
    "# Read the content of the file into a list of lines\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "columns = lines[target_row].strip().split('\\t')  # Assuming columns are separated by tabs ('\\t')\n",
    "\n",
    "columns[target_column] = '\\t'\n",
    "lines[target_row] = '\\t'.join(columns) + '\\n'\n",
    "# Write the updated content back to the file\n",
    "with open(file_path, 'w') as file:\n",
    "    file.writelines(lines)\n",
    "\n",
    "print(\"File updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = \"../data/user_user.txt\"\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Count the number of rows\n",
    "num_rows = len(lines)\n",
    "print(num_rows)\n",
    "# Count the number of columns (assuming columns are separated by tabs '\\t')\n",
    "if num_rows > 0:\n",
    "    # Split the first line using the tab delimiter and count the elements\n",
    "    num_columns = len(lines[0].strip().split('\\t'))\n",
    "else:\n",
    "    # If there are no rows, there are no columns\n",
    "    num_columns = 0\n",
    "\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/user_user.txt\", sep=\" \") # open user_user\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_users(Num_samples_I,Num_samples_F):\n",
    "    newpath = f\"../data/filter_S_I_{Num_samples_I}_S_F_{Num_samples_F}/\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "\n",
    "    df1 = pd.read_csv(\"../data/dictonary_user.txt\", sep=\" \")\n",
    "    \n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    \n",
    "    df1['cod_name'] = df1['cod_name'].astype(str).str.zfill(6)\n",
    "    \n",
    "    new_file = newpath+f\"user_user_NumSI_{Num_samples_I}_NumSF_{Num_samples_F}.txt\"\n",
    "    \n",
    "    ter_ = 50 # To save of i multiply 50\n",
    "\n",
    "    # If  file with changers exist -> open it\n",
    "    if(os.path.exists(new_file)):\n",
    "        df = pd.read_csv(new_file, sep=\" \")\n",
    "    \n",
    "    # Else -> open original file\n",
    "    else:\n",
    "        df = pd.read_csv(\"../data/user_user.txt\", sep=\" \")\n",
    "    \n",
    "    for i in range(Num_samples_I,Num_samples_F):\n",
    "        t1_start = process_time() \n",
    "\n",
    "        df.replace(to_replace=df1['name'].values[i],value=df1['cod_name'].values[i],inplace=True)\n",
    "\n",
    "        t1_stop = process_time()\n",
    "        \n",
    "        print(f\"term = {i}, rest = {(Num_samples_F-Num_samples_I)-i} | time= {(t1_stop-t1_start):.5f}s, estimated_time_to_finish={((t1_stop-t1_start)*((Num_samples_F-Num_samples_I)-i)):.5f}s\")\n",
    "        if(i/ter_ % 1==0 and i!=0):\n",
    "            df.to_csv(newpath+f\"user_user_NumSI_{Num_samples_I}_NumSF_{Num_samples_F}.txt\",sep=\" \",index=False)\n",
    "        \n",
    "    hist_file = pd.DataFrame(data={\"time\":[Num_samples_F - Num_samples_I]})\n",
    "    hist_file.to_csv(newpath+\"hist_user_user.txt\",sep=\" \",index=False)\n",
    "    df.to_csv(new_file,sep=\" \",index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_start = process_time() \n",
    "df = pd.read_csv(\"../data/user_user.txt\", sep=\" \")\n",
    "t1_stop = process_time() \n",
    "T =t1_stop-t1_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3416628 * T)/(60*60*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/user_user.txt\",sep=\" \")\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_total_data(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_h = 16 # hours\n",
    "Num_samples = number_samples_for_hour(time_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictonary_name_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1\n",
    "mapping_users(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_total_data(num_threads=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
